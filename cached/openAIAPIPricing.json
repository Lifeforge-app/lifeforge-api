{
  "GPT-4o": {
    "description": "GPT-4o is our most advanced multimodal model that’s faster and cheaper than GPT-4 Turbo with stronger vision capabilities. The model has 128K context and an October 2023 knowledge cutoff.",
    "data": {
      "gpt-4o": [
        {
          "single": {
            "amount": 2.5,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 1.25,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 1.25,
            "usage": "1M cached** input tokens"
          }
        },
        {
          "single": {
            "amount": 10,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 5,
            "usage": "1M output tokens"
          }
        }
      ],
      "gpt-4o-2024-11-20": [
        {
          "single": {
            "amount": 2.5,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 1.25,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 1.25,
            "usage": "1M cached** input tokens"
          }
        },
        {
          "single": {
            "amount": 10,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 5,
            "usage": "1M output tokens"
          }
        }
      ],
      "gpt-4o-2024-08-06": [
        {
          "single": {
            "amount": 2.5,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 1.25,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 1.25,
            "usage": "1M cached** input tokens"
          }
        },
        {
          "single": {
            "amount": 10,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 5,
            "usage": "1M output tokens"
          }
        }
      ],
      "gpt-4o-audio-preview": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 2.5,
              "usage": "1M input tokens"
            },
            {
              "amount": 10,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 40,
              "usage": "1M input tokens"
            },
            {
              "amount": 80,
              "usage": "1M output tokens"
            }
          ]
        }
      ],
      "gpt-4o-audio-preview-2024-12-17": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 2.5,
              "usage": "1M input tokens"
            },
            {
              "amount": 10,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 40,
              "usage": "1M input tokens"
            },
            {
              "amount": 80,
              "usage": "1M output tokens"
            }
          ]
        }
      ],
      "gpt-4o-audio-preview-2024-10-01": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 2.5,
              "usage": "1M input tokens"
            },
            {
              "amount": 10,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 100,
              "usage": "1M input tokens"
            },
            {
              "amount": 200,
              "usage": "1M output tokens"
            }
          ]
        }
      ],
      "gpt-4o-2024-05-13": [
        {
          "single": {
            "amount": 5,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 2.5,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 15,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 7.5,
            "usage": "1M output tokens"
          }
        }
      ]
    }
  },
  "GPT-4o mini": {
    "description": "GPT-4o mini is our most cost-efficient small model that’s smarter and cheaper than GPT-3.5 Turbo, and has vision capabilities. ",
    "data": {
      "gpt-4o-mini ": [
        {
          "single": {
            "amount": 0.15,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 0.075,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 0.075,
            "usage": "1M cached** input tokens"
          }
        },
        {
          "single": {
            "amount": 0.6,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 0.3,
            "usage": "1M output tokens"
          }
        }
      ],
      "gpt-4o-mini-2024-07-18": [
        {
          "single": {
            "amount": 0.15,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 0.075,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 0.075,
            "usage": "1M cached** input tokens"
          }
        },
        {
          "single": {
            "amount": 0.6,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 0.3,
            "usage": "1M output tokens"
          }
        }
      ],
      "gpt-4o-mini-audio-preview": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 0.15,
              "usage": "1M input tokens"
            },
            {
              "amount": 0.6,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 10,
              "usage": "1M input tokens"
            },
            {
              "amount": 20,
              "usage": "1M output tokens"
            }
          ]
        }
      ],
      "gpt-4o-mini-audio-preview-2024-12-17": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 0.15,
              "usage": "1M input tokens"
            },
            {
              "amount": 0.6,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 10,
              "usage": "1M input tokens"
            },
            {
              "amount": 20,
              "usage": "1M output tokens"
            }
          ]
        }
      ]
    }
  },
  "OpenAI o1": {
    "description": "o1 is our most powerful reasoning model that supports tools, Structured Outputs, and vision. The model has 200K context and an October 2023 knowledge cutoff.",
    "data": {
      "o1": [
        {
          "single": {
            "amount": 15,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 7.5,
            "usage": "1M cached* input tokens"
          }
        },
        {
          "single": {
            "amount": 60,
            "usage": "1M output** tokens"
          }
        }
      ],
      "o1-2024-12-17": [
        {
          "single": {
            "amount": 15,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 7.5,
            "usage": "1M cached* input tokens"
          }
        },
        {
          "single": {
            "amount": 60,
            "usage": "1M output** tokens"
          }
        }
      ],
      "o1-preview": [
        {
          "single": {
            "amount": 15,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 7.5,
            "usage": "1M cached* input tokens"
          }
        },
        {
          "single": {
            "amount": 60,
            "usage": "1M output** tokens"
          }
        }
      ],
      "o1-preview-2024-09-12": [
        {
          "single": {
            "amount": 15,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 7.5,
            "usage": "1M cached* input tokens"
          }
        },
        {
          "single": {
            "amount": 60,
            "usage": "1M output** tokens"
          }
        }
      ]
    }
  },
  "OpenAI o1-mini": {
    "description": "o1-mini is our small reasoning model that thinks faster than o1 and is optimized for coding and math. ",
    "data": {
      "o1-mini": [
        {
          "single": {
            "amount": 3,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 1.5,
            "usage": "1M cached* input tokens"
          }
        },
        {
          "single": {
            "amount": 12,
            "usage": "1M output** tokens"
          }
        }
      ],
      "o1-mini-2024-09-12": [
        {
          "single": {
            "amount": 3,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 1.5,
            "usage": "1M cached* input tokens"
          }
        },
        {
          "single": {
            "amount": 12,
            "usage": "1M output** tokens"
          }
        }
      ]
    }
  },
  "Embedding models": {
    "description": "Build advanced search, clustering, topic modeling, and classification functionality with our embeddings offering.",
    "data": {
      "text-embedding-3-small": [
        {
          "single": {
            "amount": 0.02,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 0.01,
            "usage": "1M tokens"
          }
        }
      ],
      "text-embedding-3-large": [
        {
          "single": {
            "amount": 0.13,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 0.065,
            "usage": "1M tokens"
          }
        }
      ],
      "ada v2": [
        {
          "single": {
            "amount": 0.1,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 0.05,
            "usage": "1M tokens"
          }
        }
      ]
    }
  },
  "Fine-tuning models": {
    "description": "Create your own custom models by fine-tuning our base models with your training data. Once you fine-tune a model, you’ll be billed only for the tokens you use in requests to that model.",
    "data": {
      "gpt-4o-2024-08-06": [
        {
          "single": {
            "amount": 3.75,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 1.875,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 1.875,
            "usage": "1M cached** input tokens"
          }
        },
        {
          "single": {
            "amount": 15,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 7.5,
            "usage": "1M output tokens"
          }
        },
        {
          "single": {
            "amount": 25,
            "usage": "1M training tokens"
          }
        }
      ],
      "gpt-4o-mini-2024-07-18": [
        {
          "single": {
            "amount": 0.3,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 0.15,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 0.15,
            "usage": "1M cached** input tokens"
          }
        },
        {
          "single": {
            "amount": 1.2,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 0.6,
            "usage": "1M output tokens"
          }
        },
        {
          "single": {
            "amount": 3,
            "usage": "1M training tokens"
          }
        }
      ],
      "gpt-3.5-turbo": [
        {
          "single": {
            "amount": 3,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 1.5,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 6,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 3,
            "usage": "1M output tokens"
          }
        },
        {
          "single": {
            "amount": 8,
            "usage": "1M training tokens"
          }
        }
      ],
      "davinci-002": [
        {
          "single": {
            "amount": 12,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 6,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 12,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 6,
            "usage": "1M output tokens"
          }
        },
        {
          "single": {
            "amount": 6,
            "usage": "1M training tokens"
          }
        }
      ],
      "babbage-002": [
        {
          "single": {
            "amount": 1.6,
            "usage": "1M input tokens"
          },
          "batch": {
            "amount": 0.8,
            "usage": "1M input tokens"
          }
        },
        {
          "single": {
            "amount": 1.6,
            "usage": "1M output tokens"
          },
          "batch": {
            "amount": 0.8,
            "usage": "1M output tokens"
          }
        },
        {
          "single": {
            "amount": 0.4,
            "usage": "1M training tokens"
          }
        }
      ]
    }
  },
  "Realtime API": {
    "description": "The Realtime API lets developers build low-latency, multimodal experiences, including speech-to-speech capabilities. Text and audio processed by the Realtime API are priced separately.",
    "data": {
      "gpt-4o-realtime-preview": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 5,
              "usage": "1M input tokens"
            },
            {
              "amount": 2.5,
              "usage": "1M cached* input tokens"
            },
            {
              "amount": 20,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 40,
              "usage": "1M input tokens"
            },
            {
              "amount": 2.5,
              "usage": "1M cached* input tokens"
            },
            {
              "amount": 80,
              "usage": "1M output tokens"
            }
          ]
        }
      ],
      "gpt-4o-realtime-preview-2024-12-17": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 5,
              "usage": "1M input tokens"
            },
            {
              "amount": 2.5,
              "usage": "1M cached* input tokens"
            },
            {
              "amount": 20,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 40,
              "usage": "1M input tokens"
            },
            {
              "amount": 2.5,
              "usage": "1M cached* input tokens"
            },
            {
              "amount": 80,
              "usage": "1M output tokens"
            }
          ]
        }
      ],
      "gpt-4o-realtime-preview-2024-10-01": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 5,
              "usage": "1M input tokens"
            },
            {
              "amount": 2.5,
              "usage": "1M cached** input tokens"
            },
            {
              "amount": 20,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio*",
          "items": [
            {
              "amount": 100,
              "usage": "1M input tokens"
            },
            {
              "amount": 20,
              "usage": "1M cached** input tokens"
            },
            {
              "amount": 200,
              "usage": "1M output tokens"
            }
          ]
        }
      ],
      "gpt-4o-mini-realtime-preview": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 0.6,
              "usage": "1M input tokens"
            },
            {
              "amount": 0.3,
              "usage": "1M cached* input tokens"
            },
            {
              "amount": 2.4,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 10,
              "usage": "1M input tokens"
            },
            {
              "amount": 0.3,
              "usage": "1M cached* input tokens"
            },
            {
              "amount": 20,
              "usage": "1M output tokens"
            }
          ]
        }
      ],
      "gpt-4o-mini-realtime-preview-2024-12-17": [
        {
          "type": "Text",
          "items": [
            {
              "amount": 0.6,
              "usage": "1M input tokens"
            },
            {
              "amount": 0.3,
              "usage": "1M cached* input tokens"
            },
            {
              "amount": 2.4,
              "usage": "1M output tokens"
            }
          ]
        },
        {
          "type": "Audio",
          "items": [
            {
              "amount": 10,
              "usage": "1M input tokens"
            },
            {
              "amount": 0.3,
              "usage": "1M cached* input tokens"
            },
            {
              "amount": 20,
              "usage": "1M output tokens"
            }
          ]
        }
      ]
    }
  },
  "Assistants API": {
    "description": "The Assistants API and its tools make it easy for developers to build AI assistants in their applications. The tokens used for the Assistant API are billed at the chosen language model's per-token input / output rates. ",
    "data": {
      "Code Interpreter": [
        {
          "single": {
            "amount": 0.03,
            "usage": "session"
          }
        }
      ],
      "File Search": [
        {
          "single": {
            "amount": 0.1,
            "usage": "GB of vector-storage per day (1 GB free)"
          }
        }
      ]
    }
  },
  "Image models": {
    "description": "Build DALL·E directly into your apps to generate and edit novel images and art. DALL·E 3 is the highest quality model and DALL·E 2 is optimized for lower cost.",
    "data": {
      "DALL·E 3": [
        {
          "quality": "Standard",
          "resolution": [
            [
              1024,
              1024
            ]
          ],
          "price": {
            "amount": 0.04,
            "usage": "image"
          }
        },
        {
          "quality": "Standard",
          "resolution": [
            [
              1024,
              1792
            ],
            [
              1792,
              1024
            ]
          ],
          "price": {
            "amount": 0.08,
            "usage": "image"
          }
        },
        {
          "quality": "HD",
          "resolution": [
            [
              1024,
              1024
            ]
          ],
          "price": {
            "amount": 0.08,
            "usage": "image"
          }
        },
        {
          "quality": "HD",
          "resolution": [
            [
              1024,
              1792
            ],
            [
              1792,
              1024
            ]
          ],
          "price": {
            "amount": 0.12,
            "usage": "image"
          }
        }
      ],
      "DALL·E 2": [
        {
          "quality": "",
          "resolution": [
            [
              1024,
              1024
            ]
          ],
          "price": {
            "amount": 0.02,
            "usage": "image"
          }
        },
        {
          "quality": "",
          "resolution": [
            [
              512,
              512
            ]
          ],
          "price": {
            "amount": 0.018,
            "usage": "image"
          }
        },
        {
          "quality": "",
          "resolution": [
            [
              256,
              256
            ]
          ],
          "price": {
            "amount": 0.016,
            "usage": "image"
          }
        }
      ]
    }
  },
  "Audio models": {
    "description": "Whisper can transcribe speech into text and translate many languages into English.  Text-to-speech (TTS) can convert text into spoken audio.",
    "data": {
      "Whisper": [
        {
          "single": {
            "amount": 0.006,
            "usage": "minute (rounded to the nearest second)"
          }
        }
      ],
      "TTS": [
        {
          "single": {
            "amount": 15,
            "usage": "1M characters"
          }
        }
      ],
      "TTS HD": [
        {
          "single": {
            "amount": 30,
            "usage": "1M characters"
          }
        }
      ]
    }
  },
  "Other models": {
    "description": "While we continuously improve our latest models, here is a list of other models that we support.",
    "data": {
      "chatgpt-4o-latest": [
        {
          "single": {
            "amount": 5,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 15,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-4-turbo": [
        {
          "single": {
            "amount": 10,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 30,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-4-turbo-2024-04-09": [
        {
          "single": {
            "amount": 10,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 30,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-4": [
        {
          "single": {
            "amount": 30,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 60,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-4-32k": [
        {
          "single": {
            "amount": 60,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 120,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-4-0125-preview": [
        {
          "single": {
            "amount": 10,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 30,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-4-1106-preview": [
        {
          "single": {
            "amount": 10,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 30,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-4-vision-preview": [
        {
          "single": {
            "amount": 10,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 30,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-3.5-turbo-0125": [
        {
          "single": {
            "amount": 0.5,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 1.5,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-3.5-turbo-instruct": [
        {
          "single": {
            "amount": 1.5,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 2,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-3.5-turbo-1106": [
        {
          "single": {
            "amount": 1,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 2,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-3.5-turbo-0613": [
        {
          "single": {
            "amount": 1.5,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 2,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-3.5-turbo-16k-0613": [
        {
          "single": {
            "amount": 3,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 4,
            "usage": "1M tokens"
          }
        }
      ],
      "gpt-3.5-turbo-0301": [
        {
          "single": {
            "amount": 1.5,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 2,
            "usage": "1M tokens"
          }
        }
      ],
      "davinci-002": [
        {
          "single": {
            "amount": 2,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 2,
            "usage": "1M tokens"
          }
        }
      ],
      "babbage-002": [
        {
          "single": {
            "amount": 0.4,
            "usage": "1M tokens"
          },
          "batch": {
            "amount": 0.4,
            "usage": "1M tokens"
          }
        }
      ]
    }
  }
}